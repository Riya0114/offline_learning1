{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a2df2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train_model_colab.ipynb\n",
    "# This is a Google Colab notebook - save with .ipynb extension\n",
    "\n",
    "# Title: Offline Learning - Risk Model Training\n",
    "# Description: Train ML model for student risk prediction\n",
    "# Author: Your Name\n",
    "# Date: 2024\n",
    "\n",
    "# ============================================\n",
    "# 1. SETUP & INSTALL DEPENDENCIES\n",
    "# ============================================\n",
    "\n",
    "!pip install scikit-learn==1.3.2 pandas==2.1.3 numpy==1.26.2 joblib==1.3.2\n",
    "\n",
    "# ============================================\n",
    "# 2. MOUNT GOOGLE DRIVE (Save models/data)\n",
    "# ============================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project folder in Drive\n",
    "import os\n",
    "project_path = '/content/drive/MyDrive/offline_learning'\n",
    "os.makedirs(project_path, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# 3. DOWNLOAD YOUR PROJECT FILES\n",
    "# ============================================\n",
    "\n",
    "# Option A: Upload manually\n",
    "print(\"Please upload these files to Colab:\")\n",
    "print(\"1. Backend/ml_model.py\")\n",
    "print(\"2. train_model.py\")\n",
    "print(\"3. Any dataset files\")\n",
    "\n",
    "# Option B: Clone from GitHub (if you push first)\n",
    "# !git clone https://github.com/YOUR_USERNAME/offline-learning.git\n",
    "# %cd offline-learning\n",
    "\n",
    "# ============================================\n",
    "# 4. TRAIN THE RISK PREDICTION MODEL\n",
    "# ============================================\n",
    "\n",
    "# Import your ML model class\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "# Create a simplified training script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "print(\"ðŸ“Š Training Risk Prediction Model...\")\n",
    "\n",
    "# ============================================\n",
    "# 5. CREATE SAMPLE DATA (Replace with your actual data)\n",
    "# ============================================\n",
    "\n",
    "# Generate synthetic training data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Features based on your ml_model.py\n",
    "data = {\n",
    "    'attendance_rate': np.random.uniform(40, 100, n_samples),\n",
    "    'avg_score': np.random.uniform(30, 95, n_samples),\n",
    "    'study_consistency': np.random.uniform(1, 5, n_samples),\n",
    "    'activity_completion_rate': np.random.uniform(50, 100, n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create risk labels based on rules (similar to your logic)\n",
    "def calculate_risk(row):\n",
    "    if row['attendance_rate'] < 50 or row['avg_score'] < 40:\n",
    "        return 'high'\n",
    "    elif row['attendance_rate'] < 70 or row['avg_score'] < 60:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "\n",
    "df['risk_level'] = df.apply(calculate_risk, axis=1)\n",
    "\n",
    "print(f\"Dataset created: {len(df)} samples\")\n",
    "print(\"Risk level distribution:\")\n",
    "print(df['risk_level'].value_counts())\n",
    "\n",
    "# ============================================\n",
    "# 6. TRAIN MODEL\n",
    "# ============================================\n",
    "\n",
    "# Features and target\n",
    "features = ['attendance_rate', 'avg_score', 'study_consistency', 'activity_completion_rate']\n",
    "X = df[features]\n",
    "y = df['risk_level']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_score = model.score(X_train_scaled, y_train)\n",
    "test_score = model.score(X_test_scaled, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Model trained successfully!\")\n",
    "print(f\"   Training accuracy: {train_score:.2%}\")\n",
    "print(f\"   Testing accuracy: {test_score:.2%}\")\n",
    "print(f\"   Classes: {model.classes_}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# ============================================\n",
    "# 7. SAVE MODEL TO GOOGLE DRIVE\n",
    "# ============================================\n",
    "\n",
    "# Save the model (same format as your risk_model.pkl)\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "model_path = f'{project_path}/risk_model_colab.pkl'\n",
    "joblib.dump(model_data, model_path)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Model saved to Google Drive:\")\n",
    "print(f\"   {model_path}\")\n",
    "\n",
    "# ============================================\n",
    "# 8. DOWNLOAD MODEL TO LOCAL COMPUTER\n",
    "# ============================================\n",
    "\n",
    "# Download the model file\n",
    "from google.colab import files\n",
    "files.download(model_path)\n",
    "\n",
    "print(\"\\nâ¬‡ï¸ Model downloaded to your computer!\")\n",
    "print(\"Rename it to 'risk_model.pkl' and replace your local file.\")\n",
    "\n",
    "# ============================================\n",
    "# 9. TEST PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nðŸ§ª Testing predictions...\")\n",
    "\n",
    "# Test with sample student\n",
    "test_student = {\n",
    "    'attendance_rate': 85,\n",
    "    'avg_score': 75,\n",
    "    'study_consistency': 3.5,\n",
    "    'activity_completion_rate': 90\n",
    "}\n",
    "\n",
    "# Prepare input\n",
    "X_test = pd.DataFrame([test_student])[features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(X_test_scaled)[0]\n",
    "probabilities = model.predict_proba(X_test_scaled)[0]\n",
    "\n",
    "print(f\"\\nTest Student:\")\n",
    "for key, value in test_student.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nPredicted Risk: {prediction}\")\n",
    "for cls, prob in zip(model.classes_, probabilities):\n",
    "    print(f\"  P({cls}) = {prob:.2%}\")\n",
    "\n",
    "# ============================================\n",
    "# 10. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "# Optional: Add charts if you want\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Feature importance chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "    plt.title('Feature Importance for Risk Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{project_path}/feature_importance.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Visualization saved to Google Drive\")\n",
    "    \n",
    "except:\n",
    "    print(\"\\nðŸ“Š Install matplotlib and seaborn for visualizations:\")\n",
    "    print(\"!pip install matplotlib seaborn\")\n",
    "\n",
    "# ============================================\n",
    "# 11. NEXT STEPS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download the model file (risk_model_colab.pkl)\")\n",
    "print(\"2. Rename it to 'risk_model.pkl'\")\n",
    "print(\"3. Replace your local risk_model.pkl file\")\n",
    "print(\"4. Restart your FastAPI server\")\n",
    "print(\"5. Test the new model at: http://localhost:8000/risk\")\n",
    "print(\"\\nTo share this Colab:\")\n",
    "print(\"File â†’ Share â†’ Get shareable link\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
